"""
Unit tests for text matching strategies using real data from diff_analysis_results.json.

These tests verify that our text matching algorithms can find clippings in PDF text
even with whitespace differences, ligatures, and other normalization issues.

Tests use PRODUCTION functions from amazon_coordinate_system.py.
"""

import pytest

# Import production functions
from src.kindle_parser.amazon_coordinate_system import (
    normalize_text_for_search,
    word_based_reverse_search,
    word_based_prefix_search,
)


# Test data extracted from real diff_analysis_results.json
REAL_TEST_CASES = [
    {
        "name": "table_of_contents_mismatch",
        "clipping": "Philosophers sometimes prefer to talk about computational individuation—i.e., what it takes to distinguish one physical computing system from another. We take implementation and individuation to be two sides of the same coin",
        "pdf_context": "Acknowledgments\b\nix\nIntroduction\b\n1\n\t 1.\t Physical Computation: A Philosophical Primer\t\n9\n\t 2.\t Physical and Computational Description\t\n40\n\t 3.\t Computational Description of Physical Systems\t\n64\n\t 4.\t Descriptive Strength and the Adequacy of Implementation Claims\t\n87\n\t 5.\t The Robust Mapping Account of Implementation\t\n123\n\t 6.\t Unlimited Pancomputationalism\t\n143\n\t 7.\t Limited Pancomputationalism\t\n175\n\t 8.\t Ontic Pancomputationalism\t\n203\n\t 9.\t Computation and the Mind\t\n230\n\t10.\t Conclusion: The P",
        "should_match": False,  # This is a false context - clipping is not in PDF context
        "description": "Clipping from main text incorrectly matched with table of contents"
    },
    {
        "name": "whitespace_heavy_difference",
        "clipping": "We agree that some systems can be individuated either semantically or nonsemantically and semantic individuation ofen accompanies computational individuation. Tat said, in this book we aim to identify the physical signature of computation without relying on semantic individuation",
        "pdf_context": "Acknowledgments\b\nix\nIntroduction\b\n1\n\t 1.\t Physical Computation: A Philosophical Primer\t\n9\n\t 2.\t Physical and Computational Description\t\n40\n\t 3.\t Computational Description of Physical Systems\t\n64\n\t 4.\t Descriptive Strength and the Adequacy of Implementation Claims\t\n87\n\t 5.\t The Robust Mapping Account of Implementation\t\n123\n\t 6.\t Unlimited Pancomputationalism\t\n143\n\t 7.\t Limited Pancomputationalism\t\n175\n\t 8.\t Ontic Pancomputationalism\t\n203\n\t 9.\t Computation and the Mind\t\n230\n\t10.\t Conclusion: The P",
        "should_match": False,
        "description": "Another false match with table of contents"
    },
    {
        "name": "truncated_context_match",
        "clipping": "We call these additional subsystems—subsystems whose states do not map to computational states, inputs, or outputs of CS—computationally",
        "pdf_context": "78 \nComputational Description of Physical Systems\nevolves dynamically in such a way that it contributes to implementing C (with A \ndoing whatever is required beyond the dynamical evolution of PS). In each of \nthese cases, PS′ plays a role in the implementation of a computing system CS that \nperforms C without alone being a physical implementation of CS. The physical \nsystem PS that implements CS is the reservoir PS′ together with the input layer \nand the output layer A.\nIndeed, such is the norm ",
        "should_match": False,  # Clipping is truncated and doesn't appear in context
        "description": "Truncated clipping that doesn't match provided context"
    },
    {
        "name": "short_snippet_match",
        "clipping": "possible state sequences containing c that could be generated by CS. Tis licenses the",
        "pdf_context": "Criterion PCE \n91\nThese inferences about possible physical state trajectories follow directly and \nexclusively from the occurrence of physical state s and the dynamical laws within \nwhich the physical description of PS is articulated.\nFinally, suppose that physical state s maps onto computational state c in a map- \nping from the physical description of PS to the computational definition of CS (a \nPCM). If physical state s is \"computationally equivalent\" to computational state c, \nthen the set of ",
        "should_match": False,
        "description": "Short snippet doesn't appear in wrong context"
    },
    {
        "name": "whitespace_normalized_should_match",
        "clipping": "operation on mathematical objects must be represented by operations on variables",
        "pdf_context": "Introduction\nWe are surrounded by computing devices. They are embedded in phones, cars, \nand myriad other things. They are used for everyday work, communication, and \nentertainment. They are also indispensable scientific tools, capable of running \nand displaying simulations of just about anything—­tornadoes, molecules, galax-\nies, brains, and, well, other computing devices.\nComputing devices are not the only physical systems that are widely regarded \nas implementing computations. Mainstream psyc",
        "should_match": False,
        "description": "Clipping not in provided context"
    },
    {
        "name": "ligature_and_whitespace",
        "clipping": "While this characterization includes ordinary computers, it excludes nonuniversal Turing machines, finite state automata, and most types of neural networks",
        "pdf_context": "12 \nPhysical Computation\nabstract in the sense in which mathematics is abstract, so computations that solve \nmathematical problems can be defined in terms of such variables.\nApplying ordered sets of instructions to any instance of a general problem con-\nstitutes a computation. Put another way, computation is the process of solving an \ninstance of a mathematical problem by applying, or following, an algorithm. Note \nthat although one generally thinks in terms of starting with a specified mathemat",
        "should_match": False,
        "description": "Clipping with potential ligature issues not in context"
    },
    {
        "name": "exact_match_with_newlines",
        "clipping": "These observations illustrate a concrete example",
        "pdf_context": "Criterion PCE \n97\nWhat we cannot infer from an occurrence of c2 within a five-­step sequence, \nhowever, is the computational step at which c2 occurred (third, fourth, or fifth). \nNor can we infer the trajectory that led to the occurrence of c2, even if we pre-\nsume its occurrence on the third step, the fourth step, or the fifth step.\nThese observations illustrate, within a concrete example, the information that \nthe occurrence of a computational state does and does not bear about the compu-\ntational trajectory.",
        "should_match": True,
        "description": "Should find match despite newlines in PDF"
    },
    {
        "name": "hyphenation_at_line_break",
        "clipping": "standard digital computing circuits",
        "pdf_context": "Criterion PCE \n103\n4.3.5  Criterion PCE and Conventional Electronic Computers\nThe dynamical requirements for satisfaction of PCE, which may seem quite \nrestrictive, can be straightforwardly expressed and are indeed satisfied—­by design \nand with the help of prevailing system-­environment interactions—­by the stand­\nard digital computing circuits fabricated on the silicon chips found in virtually all \nfamiliar digital computing devices.",
        "should_match": True,
        "description": "Should find match despite hyphenation: stand-ard"
    },
    {
        "name": "complex_soft_hyphen_and_linebreaks_shea_p136",
        "clipping": "A concept is a plug-and-play device with plugs at both ends. It provides an interface between the informational models and content-specific computations of special-purpose systems, at one end, and the general-purpose compositionality and content-general reasoning of deliberate thought, at the other.",
        "pdf_context": "A con-\ncept is a plug-\xadand-\xadplay device with plugs at both ends. It provides an interface between the informational models and content-\xadspecific computations of special-\xad\npurpose systems, at one end, and the general-\xadpurpose compositionality and content-\xadgeneral reasoning of deliberate thought, at the other.",
        "should_match": True,
        "description": "CRITICAL TEST: Real page 136 from Shea PDF with mixed hyphenation - regular hyphen + newline (con-\\n), soft hyphens (plug-\\xadand-\\xadplay), and combined patterns (special-\\xad\\npurpose)"
    },
    {
        "name": "kindle_extraction_errors_vs_pdf",
        "clipping": "A concept is a plug-and-play device with plugs at both ends. It provides an interface between the informational models and content-specifc computations of specialpurpose systems, at one end, and the general-purpose compositionality and content-general reasoning of deliberate thought, at the other.",
        "pdf_context": "A con-\ncept is a plug-\xadand-\xadplay device with plugs at both ends. It provides an interface between the informational models and content-\xadspecific computations of special-\xad\npurpose systems, at one end, and the general-\xadpurpose compositionality and content-\xadgeneral reasoning of deliberate thought, at the other.",
        "should_match": True,
        "description": "CRITICAL TEST: Same text but with Kindle extraction errors - 'content-specifc' (missing i) and 'specialpurpose' (no space/hyphen). Tests robustness to OCR/extraction inconsistencies."
    },
]


class TestTextNormalization:
    """Test production text normalization functions."""
    
    def test_strip_ligatures(self):
        """Test ligature stripping using production normalize_text_for_search."""
        assert normalize_text_for_search('ﬁnite') == 'fnite'   # ﬁ -> f (ligature fi -> f)
        assert normalize_text_for_search('ﬂow') == 'fow'      # ﬂ -> f (ligature fl -> f)
        assert normalize_text_for_search('oﬀer') == 'ofer'    # ﬀ -> f (ligature ff -> f)
        assert normalize_text_for_search('traﬃc') == 'trafc'  # ﬃ -> f (ligature ffi -> f)
    
    def test_whitespace_normalization(self):
        """Test whitespace normalization using production normalize_text_for_search."""
        assert normalize_text_for_search('hello    world') == 'hello world'
        assert normalize_text_for_search('hello\n\n\nworld') == 'hello world'
        assert normalize_text_for_search('hello\tworld') == 'hello world'
        assert normalize_text_for_search('stand-\nard') == 'standard'


class TestCurrentFallbackStrategy:
    """Test the current fixed-length fallback strategy."""
    
    def test_fixed_length_creates_nonsense(self):
        """Show that fixed-length truncation creates nonsense search strings."""
        clipping = "Philosophers sometimes prefer to talk about computational individuation—i.e., what it takes to distinguish one physical computing system from another."
        
        # Current strategy: take first 50 chars
        truncated_50 = clipping[:50]
        assert truncated_50 == "Philosophers sometimes prefer to talk about comput"
        # This cuts mid-word "comput" - nonsense!
        
        # Take first 30 chars
        truncated_30 = clipping[:30]
        assert truncated_30 == "Philosophers sometimes prefer "
        # Better, but loses distinctive information
    
    def test_fixed_length_loses_distinctive_features(self):
        """Show that short prefixes lose distinctive features."""
        clipping1 = "Philosophers sometimes prefer to talk about computational individuation"
        clipping2 = "Philosophers sometimes prefer to use semantic descriptions"
        
        # Both start the same - first 30 chars are identical!
        assert clipping1[:30] == clipping2[:30] == "Philosophers sometimes prefer "


class TestWordBasedFallback:
    """Test word-based fallback strategy."""
    
    def test_word_based_preserves_meaning(self):
        """Word-based truncation preserves semantic meaning."""
        clipping = "Philosophers sometimes prefer to talk about computational individuation"
        words = clipping.split()
        
        # Take last 5 words (more distinctive than first 5)
        last_5 = ' '.join(words[-5:])
        assert last_5 == "to talk about computational individuation"  # Fixed: actually 5 words
        # Clean, meaningful phrase!
        
        # Take last 50% of words
        half_point = len(words) // 2
        last_half = ' '.join(words[half_point:])
        assert "computational individuation" in last_half
    
    def test_last_words_more_distinctive(self):
        """Test that endings are more distinctive than beginnings."""
        clipping1 = "Philosophers sometimes prefer to talk about computational individuation"
        clipping2 = "Philosophers sometimes prefer to use semantic descriptions"
        
        words1 = clipping1.split()
        words2 = clipping2.split()
        
        # First 3 words - same!
        assert ' '.join(words1[:3]) == ' '.join(words2[:3])
        
        # Last 3 words - different!
        assert ' '.join(words1[-3:]) != ' '.join(words2[-3:])
        assert ' '.join(words1[-3:]) == "about computational individuation"
        assert ' '.join(words2[-3:]) == "use semantic descriptions"


class TestAdaptiveReverseSearch:
    """Test adaptive reverse search strategy."""
    
    def test_adaptive_length_based_on_clipping(self):
        """Test that search length adapts to clipping length."""
        short_clipping = "This is short"
        long_clipping = "This is a much longer clipping that contains many more words and phrases"
        
        # For short clipping, take 80% is still meaningful
        short_words = short_clipping.split()
        short_80 = ' '.join(short_words[-int(len(short_words) * 0.8):])
        assert short_80 == "is short"
        
        # For long clipping, 80% preserves lots of context
        long_words = long_clipping.split()
        long_80 = ' '.join(long_words[-int(len(long_words) * 0.8):])
        assert "much longer clipping that contains many more words and phrases" in long_80
    
    def test_reverse_search_ratios(self):
        """Test progressive ratio reduction."""
        clipping = "This is a test clipping with several words for matching"
        words = clipping.split()
        
        ratios = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5]
        
        for ratio in ratios:
            word_count = int(len(words) * ratio)
            if word_count < 3:  # Don't go too short
                break
            search_text = ' '.join(words[-word_count:])
            assert len(search_text) > 0
            # Each iteration is shorter but still meaningful
            if ratio >= 0.5:
                assert len(search_text.split()) >= 3


class TestRealDataMatching:
    """Test matching with real data using PRODUCTION functions."""
    
    @pytest.mark.parametrize("test_case", REAL_TEST_CASES)
    def test_real_cases_word_based(self, test_case):
        """Test production word-based reverse search on real data."""
        clipping_norm = normalize_text_for_search(test_case["clipping"])
        pdf_norm = normalize_text_for_search(test_case["pdf_context"])
        
        result = word_based_reverse_search(clipping_norm, pdf_norm)
        
        if test_case["should_match"]:
            assert result is not None, f"Failed to find match for: {test_case['name']}"
            print(f"✓ {test_case['name']}: Found '{result[:50]}...'")
        else:
            # Should not find false matches
            if result is not None:
                print(f"⚠ {test_case['name']}: False positive - matched '{result[:50]}...'")
    
    @pytest.mark.parametrize("test_case", REAL_TEST_CASES)
    def test_real_cases_prefix_based(self, test_case):
        """Test production word-based prefix search on real data."""
        clipping_norm = normalize_text_for_search(test_case["clipping"])
        pdf_norm = normalize_text_for_search(test_case["pdf_context"])
        
        result = word_based_prefix_search(clipping_norm, pdf_norm)
        
        if test_case["should_match"]:
            # Prefix search is a fallback, so it's OK if it doesn't match everything
            if result is not None:
                print(f"✓ {test_case['name']}: Found '{result[:50]}...'")
            else:
                print(f"⚠ {test_case['name']}: Prefix search didn't match (may need reverse search)")
        else:
            # Should not find false matches
            if result is not None:
                print(f"⚠ {test_case['name']}: False positive - matched '{result[:50]}...'")
    
    def test_combined_strategy(self):
        """Test that combining reverse + prefix search covers all valid matches."""
        true_positive_cases = [tc for tc in REAL_TEST_CASES if tc["should_match"]]
        
        for test_case in true_positive_cases:
            clipping_norm = normalize_text_for_search(test_case["clipping"])
            pdf_norm = normalize_text_for_search(test_case["pdf_context"])
            
            # Try reverse search first (more distinctive)
            result = word_based_reverse_search(clipping_norm, pdf_norm)
            
            # Fall back to prefix search
            if result is None:
                result = word_based_prefix_search(clipping_norm, pdf_norm)
            
            # At least one should match
            assert result is not None, f"Neither strategy found match for: {test_case['name']}"

# All tests use PRODUCTION functions from amazon_coordinate_system.py
# Hypothetical implementations removed - tests validate actual production behavior

if __name__ == "__main__":
    # Run tests with pytest
    pytest.main([__file__, "-v", "-s"])
